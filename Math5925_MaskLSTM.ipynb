{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cfe140e-fe3d-4945-9e51-123abf707035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c04425f-8bc2-488a-8c0f-d4729c0c2c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "#Ëøô‰∏™ÁâàÊú¨Âú®ËΩ¨ÂåñÊï∞ÊçÆÂà∞ÊØèÂ∞èÊó∂‰∏Ä‰∏™Êó∂Èó¥Ê≠•ËøáÁ®ã‰∏≠‰ΩøÁî®‰∫ÜÂπ≥ÂùáÊï∞‰Ωú‰∏∫ÊèíÂÄº\n",
    "def build_lstm_table(folder_path, freq=\"60min\"):\n",
    "    all_records = []\n",
    "\n",
    "    for file in glob.glob(os.path.join(folder_path, \"*.txt\")):\n",
    "        df = pd.read_csv(file, names=[\"Time\", \"Parameter\", \"Value\"])\n",
    "\n",
    "        df[\"Time\"] = df[\"Time\"].astype(str).str.strip()\n",
    "        df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%H:%M\", errors=\"coerce\")\n",
    "\n",
    "        wide = df.pivot_table(index=\"Time\", columns=\"Parameter\", values=\"Value\", aggfunc=\"first\")\n",
    "\n",
    "        wide.columns.name = None\n",
    "        wide = wide.reset_index()\n",
    "\n",
    "        try:\n",
    "            rid = df.loc[df[\"Parameter\"] == \"RecordID\", \"Value\"].iloc[0]\n",
    "        except IndexError:\n",
    "            rid = os.path.basename(file).split(\".\")[0]\n",
    "        wide[\"RecordID\"] = rid\n",
    "\n",
    "        for c in wide.columns:\n",
    "            if c not in [\"Time\", \"RecordID\"]:\n",
    "                wide[c] = pd.to_numeric(wide[c], errors=\"coerce\")\n",
    "\n",
    "        all_records.append(wide)\n",
    "\n",
    "    data_all = pd.concat(all_records, ignore_index=True)\n",
    "\n",
    "    uniform_records = []\n",
    "    for rid, group in data_all.groupby(\"RecordID\"):\n",
    "        group = group.sort_values(\"Time\").set_index(\"Time\")\n",
    "        numeric_cols = group.select_dtypes(include=\"number\").columns\n",
    "        resampled = group[numeric_cols].resample(freq).mean().interpolate(limit_direction=\"both\")\n",
    "        resampled[\"RecordID\"] = rid\n",
    "        uniform_records.append(resampled)\n",
    "\n",
    "    df = pd.concat(uniform_records).reset_index()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8d0948-aacb-4aff-97cf-8bc33e0d290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "#Ëøô‰∏™ÁâàÊú¨ÂØπ‰∫éÊüê‰∏™Êó∂Èó¥Ê≠•‰∏äÊ≤°ÊúâÁöÑÁöÑÊï∞ÊçÆÊ≤°ÊúâËøõË°åÊèíÂÄº\n",
    "#‰∏é‰∏Ä‰∏™ÁâàÊú¨ËøõË°åÂØπÊØîÔºå‰æãÂ¶ÇÊüêÈ°πÊåáÊ†áÂú®3Â∞èÊó∂ÂÜÖÂè™ÊµãËØï‰∫Ü‰∏ÄÊ¨°ÔºåÊàë‰ª¨Âú®‰∏ä‰∏™ÁâàÊú¨‰∏≠Â∞ÜËØ•ÊåáÊ†áÁöÑÊï∞ÊçÆ‰Ωú‰∏∫3Â∞èÊó∂ÂÜÖÊØè‰∏™Â∞èÊó∂ÈÉΩ‰∏∫Ëøô‰∏™ÊåáÊ†áÔºåËÄåËøô‰∏™ÁâàÊú¨ÂàôÂè™‰Ωú‰∏∫Á¨¨‰∏Ä‰∏™Â∞èÊó∂ÁöÑÊï∞ÊçÆ\n",
    "#ÔºåÂÖ∂‰ªñ‰∏§‰∏™Â∞èÊó∂ÁöÑËØ•ÊåáÊ†áËßÜ‰∏∫Áº∫Â§±ÂÄº\n",
    "def build_lstm_table(folder_path, freq=\"60min\"):\n",
    "    all_records = []\n",
    "\n",
    "    for file in glob.glob(os.path.join(folder_path, \"*.txt\")):\n",
    "        df = pd.read_csv(file, names=[\"Time\", \"Parameter\", \"Value\"])\n",
    "        df[\"Time\"] = pd.to_datetime(df[\"Time\"].astype(str).str.strip(), format=\"%H:%M\", errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"Time\"])\n",
    "\n",
    "        wide = df.pivot_table(index=\"Time\", columns=\"Parameter\", values=\"Value\", aggfunc=\"first\")\n",
    "        wide.columns.name = None\n",
    "        wide = wide.reset_index()\n",
    "\n",
    "        try:\n",
    "            rid = df.loc[df[\"Parameter\"] == \"RecordID\", \"Value\"].iloc[0]\n",
    "        except IndexError:\n",
    "            rid = os.path.basename(file).split(\".\")[0]\n",
    "        wide[\"RecordID\"] = rid\n",
    "\n",
    "        for c in wide.columns:\n",
    "            if c not in [\"Time\", \"RecordID\"]:\n",
    "                wide[c] = pd.to_numeric(wide[c], errors=\"coerce\")\n",
    "\n",
    "        all_records.append(wide)\n",
    "\n",
    "    data_all = pd.concat(all_records, ignore_index=True)\n",
    "\n",
    "    uniform_records = []\n",
    "    for rid, group in data_all.groupby(\"RecordID\"):\n",
    "        group = group.sort_values(\"Time\").set_index(\"Time\")\n",
    "        numeric_cols = group.select_dtypes(include=\"number\").columns\n",
    "        resampled = group[numeric_cols].resample(freq).mean()\n",
    "        resampled[\"RecordID\"] = rid\n",
    "        uniform_records.append(resampled)\n",
    "\n",
    "    df = pd.concat(uniform_records).reset_index()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1b9506-014b-4045-9f37-496e30200bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = build_lstm_table(\"./Features_group_10-Copy1\", freq=\"60min\")\n",
    "df = df.drop(columns=['Age','Gender','Height','ICUType','Weight'])\n",
    "#print(df.info())\n",
    "#print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095aa4d3-f9b5-4f03-a627-e914218e1929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RecordID  SAPS-I  SOFA  Length_of_stay  Survival  In-hospital_death\n",
      "0    142675      27    14               9         7                  1\n",
      "1    142676      12     1              31       468                  0\n",
      "2    142680      12     7              17        16                  1\n",
      "3    142683      19    15              17        -1                  0\n",
      "4    142688       3     0               9        -1                  0\n"
     ]
    }
   ],
   "source": [
    "outcomes = pd.read_csv(\"Outcomes-group_10.txt\")\n",
    "print(outcomes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e1dcc5-bc59-4ec1-884a-ea719052f949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Time  ALP  ALT  AST  Albumin   BUN  Bilirubin  \\\n",
      "0     1900-01-01 00:00:00  NaN  NaN  NaN      NaN   NaN        NaN   \n",
      "1     1900-01-01 01:00:00  NaN  NaN  NaN      NaN   NaN        NaN   \n",
      "2     1900-01-01 02:00:00  NaN  NaN  NaN      NaN  13.0        NaN   \n",
      "3     1900-01-01 03:00:00  NaN  NaN  NaN      NaN   NaN        NaN   \n",
      "4     1900-01-01 04:00:00  NaN  NaN  NaN      NaN   NaN        NaN   \n",
      "...                   ...  ...  ...  ...      ...   ...        ...   \n",
      "95038 1900-01-01 19:00:00  NaN  NaN  NaN      NaN   NaN        NaN   \n",
      "95039 1900-01-01 20:00:00  NaN  NaN  NaN      NaN   NaN        NaN   \n",
      "95040 1900-01-01 21:00:00  NaN  NaN  NaN      NaN   NaN        NaN   \n",
      "95041 1900-01-01 22:00:00  NaN  NaN  NaN      NaN   NaN        NaN   \n",
      "95042 1900-01-01 23:00:00  NaN  NaN  NaN      NaN   NaN        NaN   \n",
      "\n",
      "       Creatinine    DiasABP  FiO2  ...     pH  NIDiasABP  NIMAP  NISysABP  \\\n",
      "0             NaN        NaN   NaN  ...  7.500        NaN    NaN       NaN   \n",
      "1             NaN  72.500000   1.0  ...  7.500        NaN    NaN       NaN   \n",
      "2             0.8  71.000000   0.5  ...    NaN        NaN    NaN       NaN   \n",
      "3             NaN  60.166667   NaN  ...  7.430        NaN    NaN       NaN   \n",
      "4             NaN  51.600000   NaN  ...  7.295        NaN    NaN       NaN   \n",
      "...           ...        ...   ...  ...    ...        ...    ...       ...   \n",
      "95038         NaN  57.000000   NaN  ...    NaN        NaN    NaN       NaN   \n",
      "95039         NaN  46.000000   NaN  ...    NaN        NaN    NaN       NaN   \n",
      "95040         NaN  46.000000   0.5  ...    NaN        NaN    NaN       NaN   \n",
      "95041         NaN  40.500000   NaN  ...    NaN        NaN    NaN       NaN   \n",
      "95042         NaN  42.000000   0.5  ...    NaN        NaN    NaN       NaN   \n",
      "\n",
      "       RespRate  TroponinT  Cholesterol  TroponinI  RecordID  \\\n",
      "0           NaN        NaN          NaN        NaN    142675   \n",
      "1           NaN        NaN          NaN        NaN    142675   \n",
      "2           NaN        NaN          NaN        NaN    142675   \n",
      "3           NaN        NaN          NaN        NaN    142675   \n",
      "4           NaN        NaN          NaN        NaN    142675   \n",
      "...         ...        ...          ...        ...       ...   \n",
      "95038       NaN        NaN          NaN        NaN    152864   \n",
      "95039       NaN        NaN          NaN        NaN    152864   \n",
      "95040       NaN        NaN          NaN        NaN    152864   \n",
      "95041       NaN        NaN          NaN        NaN    152864   \n",
      "95042       NaN        NaN          NaN        NaN    152864   \n",
      "\n",
      "       In-hospital_death  \n",
      "0                      1  \n",
      "1                      1  \n",
      "2                      1  \n",
      "3                      1  \n",
      "4                      1  \n",
      "...                  ...  \n",
      "95038                  0  \n",
      "95039                  0  \n",
      "95040                  0  \n",
      "95041                  0  \n",
      "95042                  0  \n",
      "\n",
      "[95043 rows x 39 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95043 entries, 0 to 95042\n",
      "Data columns (total 39 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   Time               95043 non-null  datetime64[ns]\n",
      " 1   ALP                2119 non-null   float64       \n",
      " 2   ALT                2186 non-null   float64       \n",
      " 3   AST                2185 non-null   float64       \n",
      " 4   Albumin            1642 non-null   float64       \n",
      " 5   BUN                8257 non-null   float64       \n",
      " 6   Bilirubin          2180 non-null   float64       \n",
      " 7   Creatinine         8302 non-null   float64       \n",
      " 8   DiasABP            50752 non-null  float64       \n",
      " 9   FiO2               17172 non-null  float64       \n",
      " 10  GCS                32529 non-null  float64       \n",
      " 11  Glucose            7632 non-null   float64       \n",
      " 12  HCO3               8068 non-null   float64       \n",
      " 13  HCT                10870 non-null  float64       \n",
      " 14  HR                 85462 non-null  float64       \n",
      " 15  K                  8424 non-null   float64       \n",
      " 16  Lactate            5722 non-null   float64       \n",
      " 17  MAP                50392 non-null  float64       \n",
      " 18  MechVent           16506 non-null  float64       \n",
      " 19  Mg                 7771 non-null   float64       \n",
      " 20  Na                 7918 non-null   float64       \n",
      " 21  PaCO2              14286 non-null  float64       \n",
      " 22  PaO2               14250 non-null  float64       \n",
      " 23  Platelets          8710 non-null   float64       \n",
      " 24  SaO2               4651 non-null   float64       \n",
      " 25  SysABP             50758 non-null  float64       \n",
      " 26  Temp               37358 non-null  float64       \n",
      " 27  Urine              66073 non-null  float64       \n",
      " 28  WBC                7805 non-null   float64       \n",
      " 29  pH                 14726 non-null  float64       \n",
      " 30  NIDiasABP          41763 non-null  float64       \n",
      " 31  NIMAP              41252 non-null  float64       \n",
      " 32  NISysABP           41817 non-null  float64       \n",
      " 33  RespRate           23752 non-null  float64       \n",
      " 34  TroponinT          1658 non-null   float64       \n",
      " 35  Cholesterol        311 non-null    float64       \n",
      " 36  TroponinI          263 non-null    float64       \n",
      " 37  RecordID           95043 non-null  object        \n",
      " 38  In-hospital_death  95043 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(36), int64(1), object(1)\n",
      "memory usage: 28.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "outcomes['RecordID'] = outcomes['RecordID'].astype(str)\n",
    "df = df.merge(outcomes[['RecordID', 'In-hospital_death']], on='RecordID', how='left')\n",
    "print(df)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8385ad1-f027-4af2-9d91-dfa0661b133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "patient_ids = df[\"RecordID\"].unique()\n",
    "train_ids, test_ids = train_test_split(patient_ids, test_size=0.15, random_state=42)\n",
    "train_ids, val_ids  = train_test_split(train_ids, test_size=0.1765, random_state=42)  \n",
    "\n",
    "train_df = df[df[\"RecordID\"].isin(train_ids)]\n",
    "val_df   = df[df[\"RecordID\"].isin(val_ids)]\n",
    "test_df  = df[df[\"RecordID\"].isin(test_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa71cd28-c8ce-4531-ad05-76e108aa7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def standardize_datasets(train_df, val_df, test_df, exclude_cols=['RecordID', 'Time', 'In-hospital_death']):\n",
    "    feature_cols = [c for c in train_df.columns if c not in exclude_cols]\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    scaler.fit(train_df[feature_cols])\n",
    "\n",
    "    def transform(df):\n",
    "        df_std = df.copy()\n",
    "        df_std[feature_cols] = scaler.transform(df_std[feature_cols])\n",
    "        return df_std\n",
    "\n",
    "    train_df_std = transform(train_df)\n",
    "    val_df_std = transform(val_df)\n",
    "    test_df_std = transform(test_df)\n",
    "\n",
    "    return train_df_std, val_df_std, test_df_std, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8123a074-7d65-4f86-b4b9-6bc95c853906",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_std, val_df_std, test_df_std, scaler = standardize_datasets(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4881b30-a80c-4c3c-96e5-7a627eb09049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(df, target_col='In-hospital_death', window_size=24, step_size=1):\n",
    "    X_list, mask_list, y_list = [], [], []\n",
    "\n",
    "    for rid, sub in df.groupby('RecordID'):\n",
    "        sub = sub.sort_values('Time')\n",
    "        \n",
    "        feature_cols = [c for c in sub.columns if c not in ['RecordID', 'Time', target_col]]\n",
    "        data = sub[feature_cols].values\n",
    "        label = sub[target_col].iloc[-1]\n",
    "\n",
    "        if len(sub) < window_size:\n",
    "            continue\n",
    "\n",
    "        for start in range(0, len(sub) - window_size + 1, step_size):\n",
    "            end = start + window_size\n",
    "            window = data[start:end, :]\n",
    "            time_index = sub['Time'].iloc[start:end].values\n",
    "\n",
    "            mask = (~np.isnan(window)).astype(float)\n",
    "\n",
    "            df_window = pd.DataFrame(window, columns=feature_cols)\n",
    "            df_window['Time'] = time_index\n",
    "            df_window = df_window.set_index('Time')\n",
    "\n",
    "            df_window = df_window.interpolate(method='time', limit=6, limit_direction='both')\n",
    "            df_window = df_window.ffill().bfill()\n",
    "\n",
    "            window_filled = np.nan_to_num(df_window.values, nan=0.0)\n",
    "\n",
    "            X_list.append(window_filled)\n",
    "            mask_list.append(mask)\n",
    "            y_list.append(label)\n",
    "\n",
    "    X = np.stack(X_list)\n",
    "    mask = np.stack(mask_list)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    return X, mask, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6c5e5f1-0fac-4dad-b642-b3c4bbb8cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, mask_train, y_train = create_sliding_windows(train_df_std)\n",
    "X_val, mask_val, y_val = create_sliding_windows(val_df_std)\n",
    "X_test, mask_test, y_test = create_sliding_windows(test_df_std)\n",
    "#print(X_train, mask_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ce909bf-62e3-408c-96e3-c44e3575ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "mask_train = torch.tensor(mask_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "mask_val = torch.tensor(mask_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "mask_test = torch.tensor(mask_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a3286d1-0be3-436e-b030-73d2433513e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "class MaskConcatLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, dropout=0.3):\n",
    "        super(MaskConcatLSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim * 2,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,  \n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = torch.cat([x, mask], dim=-1)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        last_hidden = h_n[-1, :, :]\n",
    "        out = self.fc(last_hidden)\n",
    "        return self.sigmoid(out)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d2f438-3eb3-490a-bb23-462fd45cc7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloaders(X_train, mask_train, y_train,\n",
    "                      X_val, mask_val, y_val,\n",
    "                      batch_size=64):\n",
    "    y_train = y_train.unsqueeze(1)\n",
    "    y_val = y_val.unsqueeze(1)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, mask_train, y_train)\n",
    "    val_dataset   = TensorDataset(X_val, mask_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "915b7275-52ee-4f0a-bf6b-45ede7cf0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_with_mask(\n",
    "    train_loader, val_loader,\n",
    "    input_dim, hidden_dim=64, num_layers=2, dropout=0.3,\n",
    "    lr=1e-3, epochs=30, early_stopping_patience=5\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = MaskConcatLSTM(input_dim, hidden_dim, num_layers, dropout).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for Xb, Mb, yb in train_loader:\n",
    "            Xb, Mb, yb = Xb.to(device), Mb.to(device), yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(Xb, Mb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for Xb, Mb, yb in val_loader:\n",
    "                Xb, Mb, yb = Xb.to(device), Mb.to(device), yb.to(device)\n",
    "                outputs = model(Xb, Mb)\n",
    "                loss = criterion(outputs, yb)\n",
    "                val_loss += loss.item()\n",
    "                preds.append(outputs.cpu())\n",
    "                trues.append(yb.cpu())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        preds = torch.cat(preds).numpy()\n",
    "        trues = torch.cat(trues).numpy()\n",
    "\n",
    "        acc = accuracy_score(trues > 0.5, preds > 0.5)\n",
    "        auc = roc_auc_score(trues, preds)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {avg_train_loss:.4f} \"\n",
    "              f\"| Val Loss: {avg_val_loss:.4f} | ACC: {acc:.4f} | AUC: {auc:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f\"üõë Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\" best loss:ÔºàVal Loss={best_val_loss:.4f}Ôºâ\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bb7c366-4f21-4387-9a44-56b21ea4743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] | Train Loss: 0.6194 | Val Loss: 0.5902 | ACC: 0.8630 | AUC: 0.7027\n",
      "Epoch [2/30] | Train Loss: 0.5464 | Val Loss: 0.4649 | ACC: 0.8630 | AUC: 0.6999\n",
      "Epoch [3/30] | Train Loss: 0.3999 | Val Loss: 0.3696 | ACC: 0.8630 | AUC: 0.7301\n",
      "Epoch [4/30] | Train Loss: 0.3696 | Val Loss: 0.3568 | ACC: 0.8630 | AUC: 0.7577\n",
      "Epoch [5/30] | Train Loss: 0.3534 | Val Loss: 0.3509 | ACC: 0.8630 | AUC: 0.7681\n",
      "Epoch [6/30] | Train Loss: 0.3460 | Val Loss: 0.3476 | ACC: 0.8630 | AUC: 0.7711\n",
      "Epoch [7/30] | Train Loss: 0.3388 | Val Loss: 0.3467 | ACC: 0.8630 | AUC: 0.7770\n",
      "Epoch [8/30] | Train Loss: 0.3347 | Val Loss: 0.3411 | ACC: 0.8648 | AUC: 0.7788\n",
      "Epoch [9/30] | Train Loss: 0.3269 | Val Loss: 0.3383 | ACC: 0.8648 | AUC: 0.7829\n",
      "Epoch [10/30] | Train Loss: 0.3245 | Val Loss: 0.3368 | ACC: 0.8648 | AUC: 0.7866\n",
      "Epoch [11/30] | Train Loss: 0.3199 | Val Loss: 0.3342 | ACC: 0.8648 | AUC: 0.7885\n",
      "Epoch [12/30] | Train Loss: 0.3194 | Val Loss: 0.3339 | ACC: 0.8648 | AUC: 0.7907\n",
      "Epoch [13/30] | Train Loss: 0.3147 | Val Loss: 0.3338 | ACC: 0.8665 | AUC: 0.7893\n",
      "Epoch [14/30] | Train Loss: 0.3078 | Val Loss: 0.3322 | ACC: 0.8665 | AUC: 0.7927\n",
      "Epoch [15/30] | Train Loss: 0.3037 | Val Loss: 0.3361 | ACC: 0.8665 | AUC: 0.7902\n",
      "Epoch [16/30] | Train Loss: 0.3042 | Val Loss: 0.3304 | ACC: 0.8665 | AUC: 0.7927\n",
      "Epoch [17/30] | Train Loss: 0.3077 | Val Loss: 0.3332 | ACC: 0.8648 | AUC: 0.7920\n",
      "Epoch [18/30] | Train Loss: 0.3006 | Val Loss: 0.3334 | ACC: 0.8648 | AUC: 0.7920\n",
      "Epoch [19/30] | Train Loss: 0.2978 | Val Loss: 0.3363 | ACC: 0.8665 | AUC: 0.7921\n",
      "Epoch [20/30] | Train Loss: 0.2953 | Val Loss: 0.3344 | ACC: 0.8665 | AUC: 0.7913\n",
      "Epoch [21/30] | Train Loss: 0.2921 | Val Loss: 0.3346 | ACC: 0.8648 | AUC: 0.7916\n",
      "Epoch [22/30] | Train Loss: 0.2915 | Val Loss: 0.3335 | ACC: 0.8630 | AUC: 0.7905\n",
      "Epoch [23/30] | Train Loss: 0.2877 | Val Loss: 0.3304 | ACC: 0.8665 | AUC: 0.7960\n",
      "Epoch [24/30] | Train Loss: 0.2870 | Val Loss: 0.3336 | ACC: 0.8648 | AUC: 0.7933\n",
      "Epoch [25/30] | Train Loss: 0.2789 | Val Loss: 0.3390 | ACC: 0.8665 | AUC: 0.7943\n",
      "Epoch [26/30] | Train Loss: 0.2801 | Val Loss: 0.3376 | ACC: 0.8683 | AUC: 0.7936\n",
      "üõë Early stopping at epoch 26\n",
      " best loss:ÔºàVal Loss=0.3304Ôºâ\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_loader, val_loader = build_dataloaders(\n",
    "    X_train, mask_train, y_train,\n",
    "    X_val, mask_val, y_val,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "\n",
    "model = train_lstm_with_mask(\n",
    "    train_loader, val_loader,\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=64,\n",
    "    num_layers=2,\n",
    "    dropout=0.3,\n",
    "    lr=1e-4,\n",
    "    epochs=30,\n",
    "    early_stopping_patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42855c-641c-45fe-b545-1feb9fd9d2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
